{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "### Advanced Lane Finding Project\n",
    "\n",
    "#### The goals / steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "1. Apply a distortion correction to raw images.\n",
    "1. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "1. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "1. Detect lane pixels and fit to find the lane boundary.\n",
    "1. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "1. Warp the detected lane boundaries back onto the original image.\n",
    "1. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import collections\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates curvature and offset for given frame using sliding window method\n",
    "def curvature_eval(binary_warped, nwindows = 20, margin = 50, minpix = 50):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # nwindows = the number of sliding windows\n",
    "    # margin = width of the windows +/- margin\n",
    "    # minpix = minimum number of pixels found to recenter window\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\\\n",
    "                          (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\\\n",
    "                           (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30.0/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate radii of curvature\n",
    "    y_eval = binary_warped.shape[0] - 1 # position at which curvature is calculated\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Calculate offset of car assuming dashcam is mounted at car centerline\n",
    "    offset_val = xm_per_pix * 0.5 * (binary_warped.shape[1] - (leftx_base + rightx_base))\n",
    "    \n",
    "    if offset_val < 0:\n",
    "        offset_dir = 'left'\n",
    "    else:\n",
    "        offset_dir = 'right'\n",
    "    offset = {'offset_val':offset_val, 'offset_dir':offset_dir}\n",
    "    \n",
    "    return {'left_fit':left_fit,'right_fit':right_fit, 'nonzerox':nonzerox,'nonzeroy':nonzeroy,\\\n",
    "            'left_lane_inds':left_lane_inds,'right_lane_inds':right_lane_inds,\\\n",
    "            'left_curverad':left_curverad, 'right_curverad':right_curverad,\\\n",
    "            'right_fit_cr':right_fit_cr,'offset':offset, 'out_img':out_img }\n",
    "\n",
    "# Projects the identified lane lines back down to the road\n",
    "def map_color(Minv, warped, undist, left_fitx, right_fitx, ploty):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "# Define a function that takes curvature, offset and maps them onto a frame\n",
    "def map_curv(img, curvature, offset):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX;\n",
    "    offset_val = offset['offset_val']\n",
    "    offset_dir = offset['offset_dir']\n",
    "    curv_text = 'Radius of curvature is: ' + str(curvature) + ' m' \n",
    "    offset_text = 'Car is offset: ' + str(abs(offset_val)) + ' m towards ' + offset_dir\n",
    "    cv2.putText(img, curv_text, (50, 50), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, offset_text, (50, 100), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return img               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_path = 'test_images/calibration_wide/GO*.jpg'\n",
    "save_path = 'test_images/calibration_wide/'\n",
    "chessboard_size = [9, 6]\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "objpoints, imgpoints = camera_calibrate(chessboard_size, open_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/calib3d/src/calibration.cpp:3681: error: (-215:Assertion failed) nimages > 0 in function 'calibrateCameraRO'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-94112a2979f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcalib3_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/calibration_wide/test_image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcalib3_und_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mundistort_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalib3_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Visualize undistortion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalib3_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-af251e3b519d>\u001b[0m in \u001b[0;36mundistort_img\u001b[0;34m(img, objpoints, imgpoints)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Do camera calibration given object points and image points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/calib3d/src/calibration.cpp:3681: error: (-215:Assertion failed) nimages > 0 in function 'calibrateCameraRO'\n"
     ]
    }
   ],
   "source": [
    "calib3_img = mpimg.imread('test_images/calibration_wide/test_image.jpg')\n",
    "calib3_und_img = undistort_img(calib3_img, objpoints, imgpoints)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(calib3_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(calib3_und_img)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline (single image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1. Undistort image\n",
    "# load test image to undistort\n",
    "load_path = 'test_images/test' + str(random.randint(1,6)) + '.jpg'\n",
    "img = mpimg.imread(load_path)\n",
    "und_img = undistort_img(img, objpoints, imgpoints)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(und_img)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 2. Create a thresholded binary image\n",
    "ksize = 5 # Sobel kernel size, choose a larger odd number to smooth gradient measurements\n",
    "img = und_img\n",
    "# Apply each of the thresholding functions\n",
    "gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(50, 100))\n",
    "s_binary = s_select(img, thresh=(150, 255))\n",
    "combined = np.zeros_like(gradx)\n",
    "combined[(((gradx == 1) & (mag_binary == 1))| (s_binary == 1))] = 1\n",
    "\n",
    "# Plot the result\n",
    "f, ax = plt.subplots(1,1, figsize=(16, 7))\n",
    "ax.imshow(combined, cmap='gray')\n",
    "ax.set_title('Thresholded Magnitude', fontsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Perform a perspective transform\n",
    "img = und_img\n",
    "persp_obj = perspective_trans(img)\n",
    "warped = persp_obj['warped']\n",
    "dst = persp_obj['dst']\n",
    "src = persp_obj['src']\n",
    "Minv = persp_obj['Minv'] # save for use in step 6\n",
    "\n",
    "pts1 = np.array(src, np.int32)\n",
    "pts1 = pts1.reshape((-1,1,2))\n",
    "cv2.polylines(img,[pts1],True,(255,0,0),3)\n",
    "\n",
    "pts2 = np.array(dst, np.int32)\n",
    "pts2 = pts2.reshape((-1,1,2))\n",
    "cv2.polylines(warped,[pts2],True,(255,0,0),3)\n",
    "\n",
    "# Visualize perspective transform\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('After Perspective Transform', fontsize=30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Find lane line pixels in a binary warped image and fit 2nd order polynomial\n",
    "# Step 5. Find radius of curvature and offset of vehicle from lane centerline\n",
    "pers_obj2 = perspective_trans(combined)\n",
    "binary_warped = pers_obj2['warped']\n",
    "curv_obj = curvature_eval(binary_warped, nwindows = 30, margin = 40, minpix = 40)\n",
    "left_fit = curv_obj['left_fit']\n",
    "right_fit = curv_obj['right_fit']\n",
    "nonzerox = curv_obj['nonzerox']\n",
    "nonzeroy = curv_obj['nonzeroy']\n",
    "left_lane_inds = curv_obj['left_lane_inds']\n",
    "right_lane_inds = curv_obj['right_lane_inds']\n",
    "offset = curv_obj['offset']\n",
    "out_img = curv_obj['out_img']\n",
    "curvature = 0.5 * (curv_obj['left_curverad'] + curv_obj['right_curverad'])\n",
    "print('The radius of curvature is: ' + str(curvature))\n",
    "print('The car is offset ' + str(offset['offset_val']) + ' towards ' + offset['offset_dir'] + '.')\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (18,9))\n",
    "ax1.imshow(binary_warped, cmap = 'gray')\n",
    "ax1.set_title('Binary warped bird\\'s eye view', fontsize = 20)\n",
    "ax2.imshow(out_img)\n",
    "ax2.plot(left_fitx, ploty, color='yellow')\n",
    "ax2.plot(right_fitx, ploty, color='yellow')\n",
    "ax2.set_title('Lane lines identified', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Overlay identified lane on original image\n",
    "plt.imshow(map_color(Minv, binary_warped, und_img, left_fitx, right_fitx, ploty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline (video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, M_inv=Minv, obj_points=objpoints, img_points=imgpoints, ksize=5, nwindows=40, margin=40, minpix=40):\n",
    "    # Step 1. Undistort image\n",
    "    und_img = undistort_img(img, obj_points, img_points) \n",
    "    # Step 2. Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(und_img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(und_img, sobel_kernel=ksize, mag_thresh=(50, 100))\n",
    "    s_binary = s_select(und_img, thresh=(150, 255))\n",
    "    combined = np.zeros_like(gradx)\n",
    "    combined[(((gradx == 1) & (mag_binary == 1))| (s_binary == 1))] = 1\n",
    "    # Step 3. Perform a perspective transform\n",
    "    persp_obj = perspective_trans(combined)\n",
    "    warped = persp_obj['warped']\n",
    "    Minv = persp_obj['Minv']\n",
    "    # Step 4. Find lane line pixels in a binary warped image and fit 2nd order polynomial\n",
    "    # Step 5. Find radius of curvature and offset of vehicle from lane centerline\n",
    "    curv_obj = curvature_eval(warped, 40, 40, 40)\n",
    "    left_fit = curv_obj['left_fit']\n",
    "    right_fit = curv_obj['right_fit']\n",
    "    left_lane_inds = curv_obj['left_lane_inds']\n",
    "    right_lane_inds = curv_obj['right_lane_inds']\n",
    "    offset = curv_obj['offset']\n",
    "    left_curverad = curv_obj['left_curverad']\n",
    "    right_curverad = curv_obj['right_curverad']\n",
    "    curvature = 0.5 * (curv_obj['left_curverad'] + curv_obj['right_curverad'])\n",
    "    # Step 6. Overlay identified lane on original image\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    lane_img = map_color(M_inv, warped, und_img, left_fitx, right_fitx, ploty)\n",
    "    lane_img = map_curv(lane_img, curvature, offset)\n",
    "    return {'left_fit':left_fit, 'right_fit':right_fit, 'lane_img':lane_img, \\\n",
    "            'offset':offset, 'curvature':curvature, 'left_lane_inds':left_lane_inds,\\\n",
    "            'right_lane_inds':right_lane_inds, 'left_curverad':left_curverad,\\\n",
    "            'right_curverad':right_curverad, 'warped':warped, 'ploty':ploty, 'M_inv':M_inv, 'und_img':und_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVideoProcessor(object):\n",
    "\n",
    "    # constructor function\n",
    "    def __init__(self):\n",
    "        # frame count\n",
    "        self.count = 0\n",
    "        # values of the last 10 fits of the line\n",
    "        self.past_frames_left = collections.deque(maxlen=10)\n",
    "        self.past_frames_right = collections.deque(maxlen=10)\n",
    "\n",
    "        # values of fits of the line for previous frame\n",
    "        self.last_fit_left = []\n",
    "        self.last_fit_right = []\n",
    "\n",
    "        # curvature for previous frame\n",
    "        self.left_curverad = []\n",
    "        self.right_curverad = []\n",
    "        self.curvature = []\n",
    "        \n",
    "        # offset for previous frame\n",
    "        self.offset = []\n",
    "        \n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit_left = None \n",
    "        self.best_fit_right = None \n",
    "\n",
    "    def pipeline_function(self, frame):\n",
    "        # your lane detection pipeline\n",
    "        if self.count < 10:\n",
    "            pipeline = process_img(frame)\n",
    "            self.past_frames_left.append(pipeline['left_fit'])\n",
    "            self.past_frames_right.append(pipeline['right_fit'])\n",
    "            if self.count == 9:\n",
    "                self.last_fit_left = pipeline['left_fit']\n",
    "                self.last_fit_right = pipeline['right_fit']\n",
    "                self.left_curverad = pipeline['left_curverad']\n",
    "                self.right_curverad = pipeline['right_curverad']\n",
    "                self.curvature = pipeline['curvature']\n",
    "                self.offset = pipeline['offset']\n",
    "                self.best_fit_left = np.mean(self.past_frames_left, axis = 0)\n",
    "                self.best_fit_right = np.mean(self.past_frames_right, axis = 0)\n",
    "            self.count += 1\n",
    "            return pipeline['lane_img']\n",
    "        \n",
    "        else:\n",
    "            # retrieve stored vals from previous frame\n",
    "            previous_left_fit = self.last_fit_left\n",
    "            previous_right_fit = self.last_fit_right\n",
    "            previous_left_curv = self.left_curverad\n",
    "            previous_right_curv = self.right_curverad\n",
    "            previous_curvature = self.curvature\n",
    "            previous_offset = self.offset\n",
    "            avg_left_fit = self.best_fit_left\n",
    "            avg_right_fit = self.best_fit_right\n",
    "            y_delx = frame.shape[0] - 1\n",
    "            prev_delx = abs(avg_left_fit[0]*y_delx**2 + avg_left_fit[1]*y_delx + avg_left_fit[2] \\\n",
    "            - avg_right_fit[0]*y_delx**2 + avg_right_fit[1]*y_delx + avg_right_fit[2])\n",
    "            \n",
    "            # process and evaluate vals for current frame\n",
    "            pipeline = process_img(frame)\n",
    "            und_img = pipeline['und_img']\n",
    "            current_left_fit = pipeline['left_fit']\n",
    "            current_right_fit = pipeline['right_fit']\n",
    "            current_left_curv = pipeline['left_curverad']\n",
    "            current_right_curv = pipeline['right_curverad']\n",
    "            current_curvature = pipeline['curvature']\n",
    "            current_offset = pipeline['offset']\n",
    "            current_delx = abs(current_left_fit[0]*y_delx**2 + current_left_fit[1]*y_delx + current_left_fit[2] \\\n",
    "            - current_right_fit[0]*y_delx**2 + current_right_fit[1]*y_delx + current_right_fit[2])         \n",
    "#             print(current_delx)\n",
    "#             print(abs(current_curvature))\n",
    "#             print(current_left_fit.shape[0])\n",
    "#             print(current_right_fit.shape[0])\n",
    "            \n",
    "            # perform sanity checks\n",
    "            if (current_left_fit.shape[0] == 0) | (current_right_fit.shape[0] == 0) | \\\n",
    "             (abs(current_curvature) > 10000) | (abs(current_curvature) < 800) | (current_delx > 1550) | (current_delx < 1100):\n",
    "                current_left_fit = avg_left_fit\n",
    "                current_right_fit = avg_right_fit\n",
    "                current_curvature = previous_curvature\n",
    "                current_offset = previous_offset\n",
    "                \n",
    "            self.past_frames_left.append(current_left_fit)\n",
    "            self.past_frames_right.append(current_right_fit)\n",
    "            current_avg_left_fit = np.mean(self.past_frames_left, axis = 0)\n",
    "            current_avg_right_fit = np.mean(self.past_frames_right, axis = 0) \n",
    "            self.best_fit_left = current_avg_left_fit \n",
    "            self.best_fit_right = current_avg_right_fit\n",
    "            self.curvature = current_curvature\n",
    "            self.offset = current_offset\n",
    "            \n",
    "            M_inv = pipeline['M_inv']\n",
    "            warped = pipeline['warped']\n",
    "            ploty = pipeline['ploty']\n",
    "            left_fitx = current_avg_left_fit[0]*ploty**2 + current_avg_left_fit[1]*ploty + current_avg_left_fit[2]\n",
    "            right_fitx = current_avg_right_fit[0]*ploty**2 + current_avg_right_fit[1]*ploty + current_avg_right_fit[2]\n",
    "            lane_img = map_color(M_inv, warped, und_img, left_fitx, right_fitx, ploty)\n",
    "            lane_img = map_curv(lane_img, current_curvature, current_offset)\n",
    "            self.count += 1\n",
    "            return lane_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_img_obj = process_img(img, Minv, objpoints, imgpoints, 5, 40, 40, 40)\n",
    "plt.imshow(process_img_obj['lane_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # load project video\n",
    "# project_video = 'project_video.mp4'\n",
    "# clip1 = VideoFileClip(project_video).subclip(0,5)\n",
    "# white_clip = clip1.fl_image(process_img) #NOTE: this function expects color images!!\n",
    "\n",
    "my_video_processor_object = MyVideoProcessor()\n",
    "output = 'project_video_output_v2_1.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "white_clip = clip.fl_image(my_video_processor_object.pipeline_function)\n",
    "\n",
    "%time white_clip.write_videofile(output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
